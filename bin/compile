#!/bin/bash
set -e

PIO_VERSION=0.9.5
PIO_BUILD=PredictionIO-${PIO_VERSION}

# Move app to a static build dir to keep paths the same between builds
# This is necessary for incremental compile, because sbt invalidates the
# cache if the path is different.
APP_BUILD_DIR=$(cd $1; pwd)
BUILD_DIR="/tmp/pio_buildpack_build_dir"
mv $APP_BUILD_DIR $BUILD_DIR
cd ${BUILD_DIR}

echo "-----> Downloading PredictionIO..."
curl -OL --silent http://download.prediction.io/${PIO_BUILD}.tar.gz
tar zxf ${PIO_BUILD}.tar.gz --warning=none
rm -rf ${BUILD_DIR}/${PIO_BUILD}/target

# Install Spark in /vendors directory
VENDORS_DIR=${BUILD_DIR}/vendors
mkdir ${VENDORS_DIR}
SPARK_VERSION=1.3.1
SPARK_DIR=${VENDORS_DIR}/spark-${SPARK_VERSION}
SPARK_FILE=spark-${SPARK_VERSION}-bin-hadoop2.6
echo "-----> Downloading Spark for PredictionIO..."
curl -O --silent http://d3kbcqa49mib13.cloudfront.net/${SPARK_FILE}.tgz
tar xf ${SPARK_FILE}.tgz
rm -rf ${SPARK_DIR} ${SPARK_FILE}.tgz
mv ${SPARK_FILE} ${SPARK_DIR}

echo "-----> Writing configurations for PredictionIO..."
cp -rn ${BUILD_DIR}/${PIO_BUILD}/* ${BUILD_DIR}/
# cp -rn ${BUILD_DIR}/${PIO_BUILD}/* ${BUILD_DIR}/
rm -rf ${PIO_BUILD} ${PIO_BUILD}.tar.gz

# Source pio-env.sh on startup
profileScript="${BUILD_DIR}/.profile.d/pio-env.sh"
mkdir -p $(dirname $profileScript)
cat ${BUILD_DIR}/conf/pio-env.sh > $profileScript

mv ${BUILD_DIR} ${APP_BUILD_DIR}
echo -e "\033[1;32m-----> PredictionIO setup done!\033[0m"
